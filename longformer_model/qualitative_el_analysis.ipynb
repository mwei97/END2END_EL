{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. See accuracy in top 2, 3, and 5 selected entities\n",
    "2. Manual check correct and incorrect samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "\n",
    "from longformer_encoder import LongEncoderRanker\n",
    "from data_process import read_dataset, process_mention_data\n",
    "from params import EvalParser\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = EvalParser()\n",
    "args = parser.parse_args([])\n",
    "\n",
    "params = args.__dict__\n",
    "params['use_longformer'] = not params['use_bert']\n",
    "\n",
    "#model_path = 'experiments/no_global_attn/bi_golden'\n",
    "model_path = 'experiments/no_global_attn/bi_pred'\n",
    "params['model_path'] = model_path\n",
    "\n",
    "params['is_biencoder'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['longformer.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "ranker = LongEncoderRanker(params)\n",
    "tokenizer = ranker.tokenizer\n",
    "device = ranker.device\n",
    "\n",
    "model_name = params['model_name']\n",
    "checkpoint = torch.load(os.path.join(model_path, model_name), map_location=device)\n",
    "# load model\n",
    "ranker.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = ranker.model\n",
    "# load optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr = params['learning_rate'])\n",
    "optim.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [00:01<00:00, 137.75it/s]\n"
     ]
    }
   ],
   "source": [
    "params['split'] = 'test'\n",
    "\n",
    "params['eval_batch_size'] = 231\n",
    "eval_batch_size = params['eval_batch_size']\n",
    "valid_samples = read_dataset(params['data_path'], params['split'])\n",
    "# check just the first document\n",
    "#valid_samples = valid_samples[:1]\n",
    "\n",
    "cand_enc_path = os.path.join(params['data_path'], f'{params[\"split\"]}_enc.json')\n",
    "valid_tensor_data = process_mention_data(\n",
    "    valid_samples,\n",
    "    tokenizer,\n",
    "    max_context_length=params['max_context_length'],\n",
    "    silent=params['silent'],\n",
    "    end_tag=params['end_tag'],\n",
    "    is_biencoder=params['is_biencoder'],\n",
    "    cand_enc_path=cand_enc_path,\n",
    "    use_longformer=params['use_longformer']\n",
    ")\n",
    "\n",
    "valid_tensor_data = TensorDataset(*valid_tensor_data)\n",
    "valid_sampler = SequentialSampler(valid_tensor_data)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_tensor_data, sampler=valid_sampler, batch_size=eval_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load candidate entities\n",
    "cand_set_enc = torch.load(params['selected_set_path'], map_location=device)\n",
    "id2label = torch.load(params['id_to_label_path'], map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(valid_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([230, 512]),\n",
       " torch.Size([230, 512]),\n",
       " torch.Size([230, 80, 1024]),\n",
       " torch.Size([230, 80]),\n",
       " torch.Size([230, 80]),\n",
       " torch.Size([230, 80]),\n",
       " torch.Size([230, 512]),\n",
       " torch.Size([230, 512]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = tuple(t.to(device) for t in batch)\n",
    "token_ids, tags, cand_enc, cand_enc_mask, label_ids, label_mask, attn_mask, global_attn_mask = batch\n",
    "tuple(t.size() for t in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranker.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_attn_mask = None\n",
    "with torch.no_grad():\n",
    "    raw_ctxt_encoding = ranker.model.get_raw_ctxt_encoding(token_ids, attn_mask, global_attn_mask)\n",
    "    ctxt_embeds = ranker.model.get_ctxt_embeds(raw_ctxt_encoding, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4053, 1024])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctxt_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ctxt_embeds, 'bi_golden_ctxt_embeds.t7')\n",
    "torch.save(ctxt_embeds, 'bi_pred_ctxt_embeds.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_acc(ctxt_embeds, cand_set_enc, k=5):\n",
    "    scores = ctxt_embeds.mm(cand_set_enc.t())\n",
    "    print(f'Scores.size(): {scores.size()}')\n",
    "    \n",
    "    true_labels = label_ids[label_mask].cpu().tolist()\n",
    "    assert len(true_labels)== scores.size(0)\n",
    "    \n",
    "    top_k = torch.topk(scores, k, dim=1)\n",
    "    top_indices = top_k[1].cpu().tolist()\n",
    "    top_labels = [[id2label[i].item() for i in l] for l in top_indices]\n",
    "    \n",
    "    top1 = top2 = top3 = top5 = 0\n",
    "\n",
    "    for i in range(scores.size(0)):\n",
    "        true_label = true_labels[i]\n",
    "        top_label = top_labels[i]\n",
    "\n",
    "        if true_label == top_label[0]:\n",
    "            top1 += 1\n",
    "        elif true_label == top_label[1]:\n",
    "            top2 += 1\n",
    "        elif true_label == top_label[2]:\n",
    "            top3 += 1\n",
    "        elif true_label in top_label[3:]:\n",
    "            top5 += 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    top5 += top1+top2+top3\n",
    "    top3 += top1+top2\n",
    "    top2 += top1\n",
    "    \n",
    "    return (scores.size(0), top1, top2, top3, top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi golden model\n",
      "Scores.size(): torch.Size([4053, 5329])\n",
      "Acc are: 0.6876, 0.7777, 0.8154, 0.8562\n"
     ]
    }
   ],
   "source": [
    "print('Bi golden model')\n",
    "total, top1, top2, top3, top5 = get_top_acc(ctxt_embeds, cand_set_enc)\n",
    "acc = [t/total for t in [top1, top2, top3, top5]]\n",
    "print(f'Acc are: {acc[0]:.4f}, {acc[1]:.4f}, {acc[2]:.4f}, {acc[3]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi pred model\n",
      "Scores.size(): torch.Size([4053, 5329])\n",
      "Acc are: 0.6625, 0.7518, 0.7866, 0.8344\n"
     ]
    }
   ],
   "source": [
    "print('Bi pred model')\n",
    "total, top1, top2, top3, top5 = get_top_acc(ctxt_embeds, cand_set_enc)\n",
    "acc = [t/total for t in [top1, top2, top3, top5]]\n",
    "print(f'Acc are: {acc[0]:.4f}, {acc[1]:.4f}, {acc[2]:.4f}, {acc[3]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual check first 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5 = torch.topk(scores, 5, dim=1)\n",
    "top_5[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indices = top_5[1]\n",
    "top_indices.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices = top_indices.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ind_list = top_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_labels = [[id2label[i].item() for i in l] for l in top_ind_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_labels), len(top_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = label_ids[label_mask].cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = top2 = top3 = top5 = 0\n",
    "\n",
    "for i, lab in enumerate(true_labels):\n",
    "    if lab == top_labels[i][0]:\n",
    "        top1 += 1\n",
    "        top2 += 1\n",
    "        top3 += 1\n",
    "        top5 += 1\n",
    "    elif lab in top_labels[i][:2]:\n",
    "        top2 += 1\n",
    "        top3 += 1\n",
    "        top5 += 1\n",
    "    elif lab in top_labels[i][:3]:\n",
    "        top3 += 1\n",
    "        top5 += 1\n",
    "    elif lab in top_labels[i]:\n",
    "        top5 += 1\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 32, 35, 36)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1, top2, top3, top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7368421052631579,\n",
       " 0.8421052631578947,\n",
       " 0.9210526315789473,\n",
       " 0.9473684210526315]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t/38 for t in [top1, top2, top3, top5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_token_ids = torch.load('../models/entity_token_ids_128.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_true_pred(i):\n",
    "#     true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cand_set_eval(ranker, valid_dataloader, params, device, cand_set_enc, id2label):\n",
    "    ranker.model.eval()\n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "    top1 = top2 = top3 = top5 = 0\n",
    "\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        assert params['is_biencoder']\n",
    "\n",
    "        token_ids, tags, cand_enc, cand_enc_mask, label_ids, label_mask, attn_mask, global_attn_mask = batch\n",
    "\n",
    "        # evaluate: not leak information about tags\n",
    "        global_attn_mask = None\n",
    "        with torch.no_grad():\n",
    "            raw_ctxt_encoding = ranker.model.get_raw_ctxt_encoding(token_ids, attn_mask, global_attn_mask)\n",
    "            ctxt_embeds = ranker.model.get_ctxt_embeds(raw_ctxt_encoding, tags)\n",
    "\n",
    "        scores = ctxt_embeds.mm(cand_set_enc.t())\n",
    "\n",
    "        true_labels = label_ids[label_mask].cpu().tolist()\n",
    "        top_5 = torch.topk(scores, 5, dim=1)\n",
    "        top_indices = top_5[1].cpu()\n",
    "#         y_true.extend(true_labels)\n",
    "#         pred_inds = torch.argmax(scores, dim=1).cpu().tolist()\n",
    "#         pred_labels = [id2label[i].item() for i in pred_inds]\n",
    "#         y_pred.extend(pred_labels)\n",
    "#         assert len(y_true)==len(y_pred)\n",
    "    \n",
    "#     acc, f1_macro, f1_micro = utils.get_metrics_result(y_true, y_pred)\n",
    "#     print(f'Accuracy: {acc:.4f}, F1 macro: {f1_macro:.4f}, F1 micro: {f1_micro:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-e2e]",
   "language": "python",
   "name": "conda-env-.conda-e2e-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
